use dotenv::dotenv;
// use http_req::{request::Method, request::Request, response, uri::Uri};
use flowsnet_platform_sdk::logger;
use github_flows::{
    get_octo, listen_to_event,
    octocrab::models::{events::payload::IssuesEventAction, issues::Issue, CommentId},
    octocrab::params::{Direction, State},
    EventPayload, GithubLogin,
};
use openai_flows::{
    chat::{ChatModel, ChatOptions},
    OpenAIFlows,
};
use std::env;
#[no_mangle]
#[tokio::main(flavor = "current_thread")]
pub async fn run() -> anyhow::Result<()> {
    dotenv().ok();
    logger::init();

    let owner = env::var("github_owner").unwrap_or("juntao".to_string());
    let repo = env::var("github_repo").unwrap_or("test".to_string());
    let trigger_phrase = env::var("trigger_phrase").unwrap_or("flows summarize".to_string());

    listen_to_event(
        &GithubLogin::Default,
        &owner,
        &repo,
        vec!["issues"],
        |payload| handler(&owner, &repo, &trigger_phrase, payload),
    )
    .await;

    Ok(())
}

async fn handler(owner: &str, repo: &str, trigger_phrase: &str, payload: EventPayload) {
    let octocrab = get_octo(&GithubLogin::Default);
    let owner_issue_handle = octocrab.issues(owner, repo);

    if let EventPayload::IssuesEvent(e) = payload {
        if e.action != IssuesEventAction::Opened {
            return;
        }
        let title = e.issue.title;
        let issue_number = e.issue.number;
        let url = match title.split_whitespace().take(2).collect::<Vec<&str>>()[..] {
            [a, b] if b.trim() == trigger_phrase => a.trim().to_string(),
            [_, _] | _ => std::process::exit(1),
        };
        log::error!("URL: {:?}", url);
        let (target_owner, target_repo) = match url.rsplitn(3, "/").take(2).collect::<Vec<&str>>()[..]
        {
            [a, b] => (b.trim().to_string(), a.trim().to_string()),
            _ => std::process::exit(1),
        };
        log::error!("Target owner, repo: {:?}, {:?}", target_owner, target_repo);
        match octocrab
            .issues(target_owner.clone(), target_repo.clone())
            .list()
            .state(State::Open)
            .direction(Direction::Descending)
            // .sort(Sort::Updated)
            .per_page(100)
            .page(1u32)
            .send()
            .await
        {
            Ok(issues_on_target) => {
                for issue in issues_on_target.items {
                    let summary = match analyze_issue(&target_owner, &target_repo, issue).await {
                        Some(s) => s,
                        None => "No summary generated".to_string(),
                    };

                    let resp = format!(
                        "{}\n{}\n{}\n
                        this result is generated by flows.network. Triggered by @{}",
                        issue.title, issue.html_url, summary, owner
                    );
                    // issues.update_comment(pull_number, resp).await.unwrap();
                    match owner_issue_handle.create_comment(issue_number, resp).await {
                        Err(error) => {
                            log::error!("Error posting resp: {}", error);
                        }
                        _ => {}
                    }
                }
            }

            Err(_e) => log::error!("Error getting issues from target: {}", _e),
        }
    }
}

pub fn squeeze_fit_remove_quoted(
    inp_str: &str,
    quote_mark: &str,
    max_len: u16,
    split: f32,
) -> String {
    let mut body = String::new();
    let mut inside_quote = false;

    for line in inp_str.lines() {
        if line.contains(quote_mark) {
            inside_quote = !inside_quote;
            continue;
        }

        if !inside_quote {
            let cleaned_line = line
                .split_whitespace()
                .filter(|word| word.len() < 150)
                .collect::<Vec<&str>>()
                .join(" ");
            body.push_str(&cleaned_line);
            body.push('\n');
        }
    }

    let body_words: Vec<&str> = body.split_whitespace().collect();
    let body_len = body_words.len();
    let n_take_from_beginning = (body_len as f32 * split) as usize;
    let n_keep_till_end = body_len - n_take_from_beginning;

    let final_text = if body_len > max_len as usize {
        let mut body_text_vec = body_words.to_vec();
        let drain_start = n_take_from_beginning;
        let drain_end = body_len - n_keep_till_end;
        body_text_vec.drain(drain_start..drain_end);
        body_text_vec.join(" ")
    } else {
        body
    };

    final_text
}

pub fn squeeze_fit_post_texts(inp_str: &str, max_len: u16, split: f32) -> String {
    let bpe = tiktoken_rs::cl100k_base().unwrap();

    let input_token_vec = bpe.encode_ordinary(inp_str);
    let input_len = input_token_vec.len();
    if input_len < max_len as usize {
        return inp_str.to_string();
    }
    // // Filter out the tokens corresponding to lines with undesired patterns
    // let mut filtered_tokens = Vec::new();
    // for line in inp_str.lines() {
    //     let mut tokens_for_line = bpe.encode_ordinary(line);
    //     if !line.contains("{{") && !line.contains("}}") {
    //         filtered_tokens.extend(tokens_for_line.drain(..));
    //     }
    // }
    let n_take_from_beginning = (input_len as f32 * split).ceil() as usize;
    let n_take_from_end = max_len as usize - n_take_from_beginning;

    let mut concatenated_tokens = Vec::with_capacity(max_len as usize);
    concatenated_tokens.extend_from_slice(&input_token_vec[..n_take_from_beginning]);
    concatenated_tokens.extend_from_slice(&input_token_vec[input_len - n_take_from_end..]);

    bpe.decode(concatenated_tokens)
        .ok()
        .map_or("failed to decode tokens".to_string(), |s| s.to_string())
}

pub async fn analyze_issue(owner: &str, repo: &str, issue: Issue) -> Option<String> {
    let openai = OpenAIFlows::new();
    let octocrab = get_octo(&GithubLogin::Default);

    let issue_creator_name = &issue.user.login;
    let issue_title = issue.title.to_string();
    let issue_number = issue.number;

    let issue_body = match &issue.body {
        Some(body) => squeeze_fit_remove_quoted(body, "```", 500, 0.6),
        None => "".to_string(),
    };

    let labels = issue
        .labels
        .iter()
        .map(|lab| lab.name.clone())
        .collect::<Vec<String>>()
        .join(", ");

    let mut all_text_from_issue = format!(
        "User '{}', opened an issue titled '{}', labeled '{}', with the following post: '{}'.",
        issue_creator_name, issue_title, labels, issue_body
    );

    match octocrab
        .issues(owner, repo)
        .list_comments(issue_number)
        .per_page(100)
        .page(1u32)
        .send()
        .await
    {
        Ok(comments_page) => {
            for comment in comments_page.items {
                let comment_body = match &comment.body {
                    Some(body) => squeeze_fit_remove_quoted(body, "```", 300, 0.6),
                    None => "".to_string(),
                };
                let commenter = &comment.user.login;
                let commenter_input = format!("{} commented: {}", commenter, comment_body);

                all_text_from_issue.push_str(&commenter_input);
            }
        }

        Err(_e) => log::error!("Error getting comments from issue: {}", _e),
    };

    let all_text_from_issue = squeeze_fit_post_texts(&all_text_from_issue, 12_000, 0.4);

    let sys_prompt_1 = &format!(
        "Given the information that user '{issue_creator_name}' opened an issue titled '{issue_title}', your task is to deeply analyze the content of the issue posts. Distill the crux of the issue, the potential solutions suggested."
    );

    // let system = &format!("As an AI co-owner of a GitHub repository, you are responsible for conducting a comprehensive analysis of GitHub issues. Your analytic focus encompasses distinct elements, including the issue's title, associated labels, body text, the identity of the issue's creator, their role, and the nature of the comments on the issue. Utilizing these data points, your task is to generate a succinct, context-aware summary of the issue.");

    let co = match all_text_from_issue.len() > 12000 {
        true => ChatOptions {
            model: ChatModel::GPT35Turbo16K,
            system_prompt: Some(sys_prompt_1),
            restart: true,
            temperature: Some(0.7),
            max_tokens: Some(192),
            ..Default::default()
        },
        false => ChatOptions {
            model: ChatModel::GPT35Turbo,
            system_prompt: Some(sys_prompt_1),
            restart: true,
            temperature: Some(0.7),
            max_tokens: Some(128),
            ..Default::default()
        },
    };
    let usr_prompt_1 = &format!(
        "Analyze the GitHub issue content: {all_text_from_issue}. Provide a concise analysis touching upon: The central problem discussed in the issue. The main solutions proposed or agreed upon. Aim for a succinct, analytical summary that stays under 128 tokens."
    );
    // let question = format!("{all_issue_texts}, concentrate on the principal arguments, suggested solutions, and areas of consensus or disagreement among the participants. From these elements, generate a concise summary of the entire issue to inform the next course of action.");

    match openai
        .chat_completion(&format!("issue_{issue_number}"), usr_prompt_1, &co)
        .await
    {
        Ok(r) => Some(r.choice),
        Err(_e) => {
            log::error!("Error generating issue summary #{}: {}", issue_number, _e);
            None
        }
    }
}

/* pub async fn github_http_post(token: &str, base_url: &str, query: &str) -> Option<Vec<u8>> {
    let base_url = Uri::try_from(base_url).unwrap();
    let mut writer = Vec::new();

    let query = serde_json::json!({"query": query});
    match Request::new(&base_url)
        .method(Method::POST)
        .header("User-Agent", "flows-network connector")
        .header("Content-Type", "application/json")
        .header("Authorization", &format!("Bearer {}", token))
        .header("Content-Length", &query.to_string().len())
        .body(&query.to_string().into_bytes())
        .send(&mut writer)
    {
        Ok(res) => {
            if !res.status_code().is_success() {
                log::error!("Github http error {:?}", res.status_code());
                return None;
            };
            Some(writer)
        }
        Err(_e) => {
            log::error!("Error getting response from Github: {:?}", _e);
            None
        }
    }
} */

/* pub async fn search_issue(github_token: &str, search_query: &str) -> Option<String> {
    #[derive(Debug, Deserialize, Clone)]
    pub struct User {
        login: Option<String>,
    }

    #[derive(Debug, Deserialize, Clone)]
    struct AssigneeNode {
        node: Option<User>,
    }

    #[derive(Debug, Deserialize, Clone)]
    struct AssigneeEdge {
        edges: Option<Vec<Option<AssigneeNode>>>,
    }

    #[derive(Debug, Deserialize, Clone)]
    struct Issue {
        url: Option<String>,
        number: Option<u64>,
        state: Option<String>,
        title: Option<String>,
        body: Option<String>,
        author: Option<User>,
        assignees: Option<AssigneeEdge>,
        #[serde(rename = "authorAssociation")]
        author_association: Option<String>,
        #[serde(rename = "createdAt")]
        created_at: Option<DateTime<Utc>>,
        #[serde(rename = "updatedAt")]
        updated_at: Option<DateTime<Utc>>,
    }

    #[derive(Debug, Deserialize)]
    struct IssueNode {
        node: Option<Issue>,
    }

    #[derive(Debug, Deserialize, Clone)]
    struct PageInfo {
        #[serde(rename = "endCursor")]
        end_cursor: Option<String>,
        #[serde(rename = "hasNextPage")]
        has_next_page: Option<bool>,
    }

    #[derive(Debug, Deserialize)]
    struct SearchResult {
        edges: Option<Vec<Option<IssueNode>>>,
        #[serde(rename = "pageInfo")]
        page_info: Option<PageInfo>,
    }

    #[derive(Debug, Deserialize)]
    struct IssueSearch {
        search: Option<SearchResult>,
    }

    #[derive(Debug, Deserialize)]
    struct IssueRoot {
        data: Option<IssueSearch>,
    }

    let base_url = "https://api.github.com/graphql";
    let mut out = String::from("ISSUES \n");

    let mut cursor = None;

    loop {
        let query = format!(
            r#"
            query {{
                search(query: "{search_query}", type: ISSUE, first: 100{after}) {{
                    edges {{
                        node {{
                            ... on Issue {{
                                url
                                number
                                state
                                title
                                body
                                author {{
                                    login
                                }}
                                assignees(first: 100) {{
                                    edges {{
                                        node {{
                                            login
                                        }}
                                    }}
                                }}
                                authorAssociation
                                createdAt
                                updatedAt
                            }}
                        }}
                    }}
                    pageInfo {{
                        endCursor
                        hasNextPage
                      }}
                }}
            }}
            "#,
            search_query = search_query,
            after = cursor
                .as_ref()
                .map_or(String::new(), |c| format!(r#", after: "{}""#, c))
        );

        match github_http_post(&github_token, base_url, &query).await {
            None => {
                log::error!("Failed to send the request: {}", base_url);
                break;
            }
            Some(response) => match serde_json::from_slice::<IssueRoot>(response.as_slice()) {
                Err(e) => {
                    log::error!("Failed to parse the response: {}", e);
                    break;
                }
                Ok(results) => {
                    if let Some(search) = &results.data.as_ref().and_then(|d| d.search.as_ref()) {
                        if let Some(edges) = &search.edges {
                            for edge in edges.iter().filter_map(|e| e.as_ref()) {
                                if let Some(issue) = &edge.node {
                                    let date = match issue.created_at {
                                        Some(date) => date.date_naive().to_string(),
                                        None => {
                                            continue;
                                        }
                                    };
                                    let title_str = match &issue.title {
                                        Some(title) => format!("Title: {},", title),
                                        None => String::new(),
                                    };
                                    let url_str = match &issue.url {
                                        Some(u) => format!("Url: {}", u),
                                        None => String::new(),
                                    };

                                    let author_str =
                                        match issue.clone().author.and_then(|a| a.login) {
                                            Some(auth) => format!("Author: {},", auth),
                                            None => String::new(),
                                        };

                                    let assignees_str = {
                                        let assignee_names = issue
                                            .assignees
                                            .as_ref()
                                            .and_then(|e| e.edges.as_ref())
                                            .map_or(Vec::new(), |assignee_edges| {
                                                assignee_edges
                                                    .iter()
                                                    .filter_map(|edge| {
                                                        edge.as_ref().and_then(|actual_edge| {
                                                            actual_edge.node.as_ref().and_then(
                                                                |user| {
                                                                    user.login.as_ref().map(
                                                                        |login_str| {
                                                                            login_str.as_str()
                                                                        },
                                                                    )
                                                                },
                                                            )
                                                        })
                                                    })
                                                    .collect::<Vec<&str>>()
                                            });

                                        if !assignee_names.is_empty() {
                                            format!("Assignees: {},", assignee_names.join(", "))
                                        } else {
                                            String::new()
                                        }
                                    };

                                    let state_str = match &issue.state {
                                        Some(s) => format!("State: {},", s),
                                        None => String::new(),
                                    };

                                    let body_str = match &issue.body {
                                        Some(body_text) if body_text.len() > 180 => {
                                            let truncated_body = body_text
                                                .chars()
                                                .take(100)
                                                .chain(
                                                    body_text
                                                        .chars()
                                                        .skip(body_text.chars().count() - 80),
                                                )
                                                .collect::<String>();

                                            format!("Body: {}", truncated_body)
                                        }
                                        Some(body_text) => format!("Body: {},", body_text),
                                        None => String::new(),
                                    };

                                    let assoc_str = match &issue.author_association {
                                        Some(association) => {
                                            format!("Author Association: {}", association)
                                        }
                                        None => String::new(),
                                    };

                                    let temp = format!(
                                            "{title_str} {url_str} Created At: {date} {author_str} {assignees_str}  {state_str} {body_str} {assoc_str}"
                                        );

                                    out.push_str(&temp);
                                    out.push_str("\n");
                                } else {
                                    continue;
                                }
                            }
                        }

                        if let Some(page_info) = &search.page_info {
                            if let Some(has_next_page) = page_info.has_next_page {
                                if has_next_page {
                                    match &page_info.end_cursor {
                                        Some(end_cursor) => {
                                            cursor = Some(end_cursor.clone());
                                            log::info!(
                                                    "Fetched a page, moving to next page with cursor: {}",
                                                    end_cursor
                                                );
                                            continue;
                                        }
                                        None => {
                                            log::error!(
                                                    "Warning: hasNextPage is true, but endCursor is None. This might result in missing data."
                                                );
                                            break;
                                        }
                                    }
                                }
                            }
                        }
                    }
                    break;
                }
            },
        }
    }

    Some(out)
} */
